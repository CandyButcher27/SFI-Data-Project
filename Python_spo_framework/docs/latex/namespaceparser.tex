\doxysection{parser Namespace Reference}
\hypertarget{namespaceparser}{}\label{namespaceparser}\index{parser@{parser}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
Dict \mbox{\hyperlink{namespaceparser_a34d250abe9dac9c81e16665c6e909eb2}{build\+\_\+tfidf\+\_\+index}} (List\mbox{[}Dict\mbox{]} chunks)
\item 
List\mbox{[}int\mbox{]} \mbox{\hyperlink{namespaceparser_aad5672a986c6d407f5b31c17a8c05b91}{retrieve\+\_\+top\+\_\+k}} (str query, Dict index, int k=5)
\item 
str \mbox{\hyperlink{namespaceparser_a0b12654d06f7ea83a3ec6c38db346f93}{assemble\+\_\+context}} (List\mbox{[}Dict\mbox{]} chunks, List\mbox{[}int\mbox{]} top\+\_\+indices)
\item 
Dict \mbox{\hyperlink{namespaceparser_acab60c601c5aac8781ad0a5e62d95b66}{call\+\_\+groq}} (str model, List\mbox{[}Dict\mbox{]} messages, float temperature=0.\+0, int max\+\_\+retries=3)
\item 
List\mbox{[}Dict\mbox{]} \mbox{\hyperlink{namespaceparser_a726ae959fffb5b4f7277e84d701dce90}{parse\+\_\+with\+\_\+llm\+\_\+groq}} (List\mbox{[}Dict\mbox{]} chunks, str prompts\+\_\+path, str groq\+\_\+model, int top\+\_\+k=5)
\item 
Dict \mbox{\hyperlink{namespaceparser_ab69cb3397febf36cea543c2f952d44de}{call\+\_\+gemini}} (str model\+\_\+gemini, List\mbox{[}Dict\mbox{]} messages, float temperature=0.\+0, int max\+\_\+retries=3)
\item 
List\mbox{[}Dict\mbox{]} \mbox{\hyperlink{namespaceparser_a32f3e62367c5448782f49bb710f41055}{parse\+\_\+with\+\_\+llm\+\_\+gemini}} (List\mbox{[}Dict\mbox{]} chunks, str prompts\+\_\+path, str gemini\+\_\+model, int top\+\_\+k=5)
\item 
Dict \mbox{\hyperlink{namespaceparser_a80105234b8f194978fd2a841e030821c}{call\+\_\+openai}} (str model, List\mbox{[}Dict\mbox{]} messages, float temperature=0.\+0, int max\+\_\+retries=3)
\item 
List\mbox{[}Dict\mbox{]} \mbox{\hyperlink{namespaceparser_af9433b9d255baa5a380bee56a8e0ff29}{parse\+\_\+with\+\_\+llm\+\_\+openai}} (List\mbox{[}Dict\mbox{]} chunks, str prompts\+\_\+path, str openai\+\_\+model, int top\+\_\+k=5)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}parser.py

This module handles the parsing of extracted PDF text chunks using either Groq or Gemini LLMs.
It supports:

1. Building a TF-IDF index over chunks for retrieval of relevant context.
2. Retrieving top-k relevant chunks for a given prompt.
3. Assembling a context block for LLM input.
4. Calling Groq or Gemini models to extract structured JSON based on prompts.
5. Parsing and returning the LLM outputs as a list of structured JSON objects.
\end{DoxyVerb}
 

\label{doc-func-members}
\Hypertarget{namespaceparser_doc-func-members}
\doxysubsection{Function Documentation}
\Hypertarget{namespaceparser_a0b12654d06f7ea83a3ec6c38db346f93}\index{parser@{parser}!assemble\_context@{assemble\_context}}
\index{assemble\_context@{assemble\_context}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{assemble\_context()}{assemble\_context()}}
{\footnotesize\ttfamily \label{namespaceparser_a0b12654d06f7ea83a3ec6c38db346f93} 
 str parser.\+assemble\+\_\+context (\begin{DoxyParamCaption}\item[{List\mbox{[}Dict\mbox{]}}]{chunks}{, }\item[{List\mbox{[}int\mbox{]}}]{top\+\_\+indices}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Assemble a human-readable context block from selected chunks.

Args:
    chunks (List[Dict]): List of chunk dictionaries.
    top_indices (List[int]): List of indices of chunks to include.

Returns:
    str: Concatenated context string with source, page, and chunk metadata.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_a34d250abe9dac9c81e16665c6e909eb2}\index{parser@{parser}!build\_tfidf\_index@{build\_tfidf\_index}}
\index{build\_tfidf\_index@{build\_tfidf\_index}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{build\_tfidf\_index()}{build\_tfidf\_index()}}
{\footnotesize\ttfamily \label{namespaceparser_a34d250abe9dac9c81e16665c6e909eb2} 
 Dict parser.\+build\+\_\+tfidf\+\_\+index (\begin{DoxyParamCaption}\item[{List\mbox{[}Dict\mbox{]}}]{chunks}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Build a TF-IDF vectorizer and matrix for a list of text chunks.

Args:
    chunks (List[Dict]): List of dicts, each containing a 'chunk' key.

Returns:
    Dict: {
        "vectorizer": TfidfVectorizer object,
        "matrix": TF-IDF feature matrix,
        "texts": List[str] of chunk texts
    }
\end{DoxyVerb}
 \Hypertarget{namespaceparser_ab69cb3397febf36cea543c2f952d44de}\index{parser@{parser}!call\_gemini@{call\_gemini}}
\index{call\_gemini@{call\_gemini}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{call\_gemini()}{call\_gemini()}}
{\footnotesize\ttfamily \label{namespaceparser_ab69cb3397febf36cea543c2f952d44de} 
 Dict parser.\+call\+\_\+gemini (\begin{DoxyParamCaption}\item[{str}]{model\+\_\+gemini}{, }\item[{List\mbox{[}Dict\mbox{]}}]{messages}{, }\item[{float }]{temperature}{ = {\ttfamily 0.0}, }\item[{int }]{max\+\_\+retries}{ = {\ttfamily 3}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Call Gemini chat model with retries.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_acab60c601c5aac8781ad0a5e62d95b66}\index{parser@{parser}!call\_groq@{call\_groq}}
\index{call\_groq@{call\_groq}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{call\_groq()}{call\_groq()}}
{\footnotesize\ttfamily \label{namespaceparser_acab60c601c5aac8781ad0a5e62d95b66} 
 Dict parser.\+call\+\_\+groq (\begin{DoxyParamCaption}\item[{str}]{model}{, }\item[{List\mbox{[}Dict\mbox{]}}]{messages}{, }\item[{float }]{temperature}{ = {\ttfamily 0.0}, }\item[{int }]{max\+\_\+retries}{ = {\ttfamily 3}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Call Groq chat model with retries.

Args:
    model (str): Groq model name.
    messages (List[Dict]): List of messages with "role" and "content".
    temperature (float): Sampling temperature.
    max_retries (int): Number of retry attempts if call fails.

Returns:
    Dict: Raw response from Groq API.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_a80105234b8f194978fd2a841e030821c}\index{parser@{parser}!call\_openai@{call\_openai}}
\index{call\_openai@{call\_openai}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{call\_openai()}{call\_openai()}}
{\footnotesize\ttfamily \label{namespaceparser_a80105234b8f194978fd2a841e030821c} 
 Dict parser.\+call\+\_\+openai (\begin{DoxyParamCaption}\item[{str}]{model}{, }\item[{List\mbox{[}Dict\mbox{]}}]{messages}{, }\item[{float }]{temperature}{ = {\ttfamily 0.0}, }\item[{int }]{max\+\_\+retries}{ = {\ttfamily 3}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Call OpenAI chat model with retries.

Args:
    model (str): OpenAI model name.
    messages (List[Dict]): List of messages with "role" and "content".
    temperature (float): Sampling temperature.
    max_retries (int): Number of retry attempts if call fails.

Returns:
    Dict: Raw response from OpenAI API.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_a32f3e62367c5448782f49bb710f41055}\index{parser@{parser}!parse\_with\_llm\_gemini@{parse\_with\_llm\_gemini}}
\index{parse\_with\_llm\_gemini@{parse\_with\_llm\_gemini}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{parse\_with\_llm\_gemini()}{parse\_with\_llm\_gemini()}}
{\footnotesize\ttfamily \label{namespaceparser_a32f3e62367c5448782f49bb710f41055} 
 List\mbox{[}Dict\mbox{]} parser.\+parse\+\_\+with\+\_\+llm\+\_\+gemini (\begin{DoxyParamCaption}\item[{List\mbox{[}Dict\mbox{]}}]{chunks}{, }\item[{str}]{prompts\+\_\+path}{, }\item[{str}]{gemini\+\_\+model}{, }\item[{int }]{top\+\_\+k}{ = {\ttfamily 5}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Parse chunks using Gemini LLM based on provided prompts.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_a726ae959fffb5b4f7277e84d701dce90}\index{parser@{parser}!parse\_with\_llm\_groq@{parse\_with\_llm\_groq}}
\index{parse\_with\_llm\_groq@{parse\_with\_llm\_groq}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{parse\_with\_llm\_groq()}{parse\_with\_llm\_groq()}}
{\footnotesize\ttfamily \label{namespaceparser_a726ae959fffb5b4f7277e84d701dce90} 
 List\mbox{[}Dict\mbox{]} parser.\+parse\+\_\+with\+\_\+llm\+\_\+groq (\begin{DoxyParamCaption}\item[{List\mbox{[}Dict\mbox{]}}]{chunks}{, }\item[{str}]{prompts\+\_\+path}{, }\item[{str}]{groq\+\_\+model}{, }\item[{int }]{top\+\_\+k}{ = {\ttfamily 5}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Parse chunks using Groq LLM based on provided prompts.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_af9433b9d255baa5a380bee56a8e0ff29}\index{parser@{parser}!parse\_with\_llm\_openai@{parse\_with\_llm\_openai}}
\index{parse\_with\_llm\_openai@{parse\_with\_llm\_openai}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{parse\_with\_llm\_openai()}{parse\_with\_llm\_openai()}}
{\footnotesize\ttfamily \label{namespaceparser_af9433b9d255baa5a380bee56a8e0ff29} 
 List\mbox{[}Dict\mbox{]} parser.\+parse\+\_\+with\+\_\+llm\+\_\+openai (\begin{DoxyParamCaption}\item[{List\mbox{[}Dict\mbox{]}}]{chunks}{, }\item[{str}]{prompts\+\_\+path}{, }\item[{str}]{openai\+\_\+model}{, }\item[{int }]{top\+\_\+k}{ = {\ttfamily 5}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Parse chunks using OpenAI LLM based on provided prompts.
\end{DoxyVerb}
 \Hypertarget{namespaceparser_aad5672a986c6d407f5b31c17a8c05b91}\index{parser@{parser}!retrieve\_top\_k@{retrieve\_top\_k}}
\index{retrieve\_top\_k@{retrieve\_top\_k}!parser@{parser}}
\doxysubsubsection{\texorpdfstring{retrieve\_top\_k()}{retrieve\_top\_k()}}
{\footnotesize\ttfamily \label{namespaceparser_aad5672a986c6d407f5b31c17a8c05b91} 
 List\mbox{[}int\mbox{]} parser.\+retrieve\+\_\+top\+\_\+k (\begin{DoxyParamCaption}\item[{str}]{query}{, }\item[{Dict}]{index}{, }\item[{int }]{k}{ = {\ttfamily 5}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Retrieve indices of top-k most similar chunks to the query.

Args:
    query (str): Query string.
    index (Dict): TF-IDF index from `build_tfidf_index`.
    k (int): Number of top results to return.

Returns:
    List[int]: List of top-k indices into index['texts'] with positive similarity.
\end{DoxyVerb}
 